{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGjtSIJROrPT"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# üì¶ PHASE 3: Model Training, Evaluation & Grad-CAM (EfficientNetB0)\n",
        "# ===============================================================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# 1. Mount Drive and set paths\n",
        "# ---------------------------------------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "BASE_DIR      = \"/content/drive/MyDrive\"\n",
        "PREP_DIR      = os.path.join(BASE_DIR, \"AML2_Project_Preprocessed\")   # Phase 2 output\n",
        "RESULTS_DIR   = os.path.join(BASE_DIR, \"AML2_Project_Results\")\n",
        "MODELS_DIR    = os.path.join(BASE_DIR, \"AML2_Project_Models\")\n",
        "META_PATH     = os.path.join(BASE_DIR, \"Skin Cancer Images\", \"metadata.csv\")\n",
        "\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "os.makedirs(MODELS_DIR,  exist_ok=True)\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# 2. Load preprocessed NumPy arrays\n",
        "# ---------------------------------------------------------------\n",
        "X_train = np.load(os.path.join(PREP_DIR, \"X_train.npy\"))\n",
        "y_train = np.load(os.path.join(PREP_DIR, \"y_train.npy\"))\n",
        "X_val   = np.load(os.path.join(PREP_DIR, \"X_val.npy\"))\n",
        "y_val   = np.load(os.path.join(PREP_DIR, \"y_val.npy\"))\n",
        "X_test  = np.load(os.path.join(PREP_DIR, \"X_test.npy\"))\n",
        "y_test  = np.load(os.path.join(PREP_DIR, \"y_test.npy\"))\n",
        "\n",
        "# Ensure correct dtypes\n",
        "X_train = X_train.astype(\"float32\")\n",
        "X_val   = X_val.astype(\"float32\")\n",
        "X_test  = X_test.astype(\"float32\")\n",
        "y_train = y_train.astype(\"int32\")\n",
        "y_val   = y_val.astype(\"int32\")\n",
        "y_test  = y_test.astype(\"int32\")\n",
        "\n",
        "print(\"Shapes:\")\n",
        "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
        "print(\"X_val:  \", X_val.shape,   \"y_val:  \", y_val.shape)\n",
        "print(\"X_test: \", X_test.shape,  \"y_test: \", y_test.shape)\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# 3. Recover class names (same encoding as Phase 2)\n",
        "# ---------------------------------------------------------------\n",
        "meta_df = pd.read_csv(META_PATH)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "le.fit(meta_df[\"diagnostic\"])\n",
        "class_names = list(le.classes_)\n",
        "num_classes = len(class_names)\n",
        "\n",
        "print(\"\\nClass mapping:\")\n",
        "for i, c in enumerate(class_names):\n",
        "    print(f\"{i} ‚Üí {c}\")\n",
        "print(\"\\nnum_classes:\", num_classes)\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# 4. Build tf.data pipelines\n",
        "# ---------------------------------------------------------------\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE   = tf.data.AUTOTUNE\n",
        "\n",
        "def make_ds(X, y, shuffle=False):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=len(X), seed=42)\n",
        "    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "train_ds = make_ds(X_train, y_train, shuffle=True)\n",
        "val_ds   = make_ds(X_val,   y_val,   shuffle=False)\n",
        "test_ds  = make_ds(X_test,  y_test,  shuffle=False)\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# 5. Data augmentation\n",
        "# ---------------------------------------------------------------\n",
        "data_augmentation = tf.keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.1),\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# 6. Build EfficientNetB0 model (transfer learning)\n",
        "# ---------------------------------------------------------------\n",
        "IMG_SIZE = 224\n",
        "\n",
        "base_model = tf.keras.applications.EfficientNetB0(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    pooling=\"avg\",\n",
        "    name=\"efficientnetb0\"  # keep this name for Grad-CAM\n",
        ")\n",
        "base_model.trainable = False  # freeze for Phase 3\n",
        "\n",
        "inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name=\"input_image\")\n",
        "x = data_augmentation(inputs)\n",
        "# images are already in [0,1]; EfficientNet expects [0,255] + preprocess\n",
        "x = tf.keras.applications.efficientnet.preprocess_input(x * 255.0)\n",
        "x = base_model(x, training=False)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"predictions\")(x)\n",
        "\n",
        "model = models.Model(inputs, outputs, name=\"EfficientNetB0_skin\")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# 7. Class weights to handle imbalance\n",
        "# ---------------------------------------------------------------\n",
        "class_weights_arr = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "class_weights = {i: class_weights_arr[i] for i in range(num_classes)}\n",
        "print(\"\\nClass weights:\")\n",
        "print(class_weights)\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# 8. Compile and train (5 epochs) ‚Äî FIXED VERSION\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]   # ‚Üê Precision/Recall REMOVED (they crash on multiclass)\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS,\n",
        "    class_weight=class_weights,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# 9. Save model\n",
        "# ---------------------------------------------------------------\n",
        "model_path = os.path.join(MODELS_DIR, \"efficientnetb0_phase3.h5\")\n",
        "model.save(model_path)\n",
        "print(f\"\\n‚úÖ Model saved to: {model_path}\")\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# 10. Plot training curves\n",
        "# ---------------------------------------------------------------\n",
        "def plot_history(hist, save_path_prefix):\n",
        "    hist_dict = hist.history\n",
        "\n",
        "    # Accuracy\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(hist_dict[\"accuracy\"], label=\"Train Acc\")\n",
        "    plt.plot(hist_dict[\"val_accuracy\"], label=\"Val Acc\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Training vs Validation Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path_prefix + \"_accuracy.png\", dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # Loss\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(hist_dict[\"loss\"], label=\"Train Loss\")\n",
        "    plt.plot(hist_dict[\"val_loss\"], label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training vs Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path_prefix + \"_loss.png\", dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history, os.path.join(RESULTS_DIR, \"efficientnetb0_phase3\"))\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# 11. Evaluation on test set + confusion matrix\n",
        "# ---------------------------------------------------------------\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "test_loss, test_acc, test_prec, test_rec = model.evaluate(test_ds, verbose=1)\n",
        "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"Test Precision: {test_prec:.4f}\")\n",
        "print(f\"Test Recall: {test_rec:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Detailed metrics: precision, recall, F1, confusion matrix\n",
        "# ------------------------------------------------------------\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Get predictions for all test samples\n",
        "y_prob = model.predict(test_ds)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "\n",
        "print(\"\\nClassification report (per class):\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=class_names))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(7,6))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    xticklabels=class_names,\n",
        "    yticklabels=class_names,\n",
        ")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix ‚Äì EfficientNetB0 (Phase 3)\")\n",
        "plt.tight_layout()\n",
        "\n",
        "cm_path = os.path.join(RESULTS_DIR, \"confusion_matrix_phase3.png\")\n",
        "plt.savefig(cm_path, dpi=150)\n",
        "plt.show()\n",
        "print(f\"Confusion matrix saved to: {cm_path}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Preview some test images with predictions\n",
        "# ------------------------------------------------------------\n",
        "def show_sample_predictions(X, y_true, y_pred, class_names, n=9):\n",
        "    idx = np.random.choice(len(X), size=n, replace=False)\n",
        "    plt.figure(figsize=(12,10))\n",
        "    for i, j in enumerate(idx):\n",
        "        plt.subplot(3, 3, i+1)\n",
        "        plt.imshow(X[j])\n",
        "        true_label = class_names[y_true[j]]\n",
        "        pred_label = class_names[y_pred[j]]\n",
        "        colour = \"green\" if y_true[j] == y_pred[j] else \"red\"\n",
        "        plt.title(f\"True: {true_label}\\nPred: {pred_label}\", color=colour)\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    grid_path = os.path.join(RESULTS_DIR, \"sample_predictions_phase3.png\")\n",
        "    plt.savefig(grid_path, dpi=150)\n",
        "    plt.show()\n",
        "    print(f\"Sample predictions grid saved to: {grid_path}\")\n",
        "\n",
        "show_sample_predictions(X_test, y_test, y_pred, class_names, n=9)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Save final model\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "MODEL_DIR = \"/content/drive/MyDrive/AML2_Project_Models\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "final_model_path = os.path.join(MODEL_DIR, \"efficientnetB0_phase3_final.keras\")\n",
        "model.save(final_model_path)\n",
        "print(f\"\\n‚úÖ Phase 3 model saved to: {final_model_path}\")"
      ],
      "metadata": {
        "id": "o_jOP4sKOstl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# üì¶ PHASE 4: Explainability with LIME + Integrated Gradients (IG)\n",
        "# ===============================================================\n",
        "\n",
        "!pip install -q lime\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import mark_boundaries\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# 1. Paths and data / model loading\n",
        "# ---------------------------------------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "BASE_DIR    = \"/content/drive/MyDrive\"\n",
        "PREP_DIR    = os.path.join(BASE_DIR, \"AML2_Project_Preprocessed\")\n",
        "RESULTS_DIR = os.path.join(BASE_DIR, \"AML2_Project_Results\")\n",
        "MODEL_DIR   = os.path.join(BASE_DIR, \"AML2_Project_Models\")\n",
        "\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "# Load preprocessed data\n",
        "X_train = np.load(os.path.join(PREP_DIR, \"X_train.npy\")).astype(\"float32\")\n",
        "y_train = np.load(os.path.join(PREP_DIR, \"y_train.npy\")).astype(\"int32\")\n",
        "X_test  = np.load(os.path.join(PREP_DIR, \"X_test.npy\")).astype(\"float32\")\n",
        "y_test  = np.load(os.path.join(PREP_DIR, \"y_test.npy\")).astype(\"int32\")\n",
        "\n",
        "print(\"X_train:\", X_train.shape, \" X_test:\", X_test.shape)\n",
        "\n",
        "# Class names (same order as in Phase 2)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "meta_path = os.path.join(BASE_DIR, \"Skin Cancer Images\", \"metadata.csv\")\n",
        "meta_df   = pd.read_csv(meta_path)\n",
        "le = LabelEncoder()\n",
        "le.fit(meta_df[\"diagnostic\"])\n",
        "class_names = list(le.classes_)\n",
        "num_classes = len(class_names)\n",
        "\n",
        "print(\"\\nClass mapping:\")\n",
        "for i, c in enumerate(class_names):\n",
        "    print(f\"{i} ‚Üí {c}\")\n",
        "\n",
        "# Load trained model (Phase 3)\n",
        "model_path = os.path.join(MODEL_DIR, \"efficientnetB0_phase3_final.keras\")\n",
        "model = tf.keras.models.load_model(model_path, compile=False)\n",
        "print(\"\\n‚úÖ Phase 3 model loaded from:\", model_path)\n",
        "\n",
        "\n",
        "# Small helper: prediction function used by LIME\n",
        "def lime_predict(images):\n",
        "    \"\"\"\n",
        "    LIME will pass a list/array of images in [0,1] range.\n",
        "    Our model was trained on [0,1] images (internal EfficientNet preprocessing),\n",
        "    so we simply cast to float32 and call model.predict().\n",
        "    \"\"\"\n",
        "    images = np.array(images).astype(\"float32\")\n",
        "    preds = model.predict(images, verbose=0)\n",
        "    return preds\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# 2. LIME ‚Äì Local explanations for an individual image\n",
        "# ===============================================================\n",
        "\n",
        "explainer = lime_image.LimeImageExplainer()\n",
        "\n",
        "# Pick a random test image (we'll reuse the same idx for IG)\n",
        "idx = np.random.randint(0, len(X_test))\n",
        "image = X_test[idx]\n",
        "true_label_idx = y_test[idx]\n",
        "true_label = class_names[true_label_idx]\n",
        "\n",
        "print(f\"\\nüîç LIME explanation for test index {idx}, true label = {true_label}\")\n",
        "\n",
        "# Run LIME\n",
        "lime_exp = explainer.explain_instance(\n",
        "    image=image,\n",
        "    classifier_fn=lime_predict,\n",
        "    top_labels=1,\n",
        "    hide_color=0,\n",
        "    num_samples=1000   # more samples ‚Üí smoother explanation, but slower\n",
        ")\n",
        "\n",
        "# Get the top predicted label from LIME\n",
        "top_label = lime_exp.top_labels[0]\n",
        "\n",
        "# Positive evidence only (regions pushing towards the predicted class)\n",
        "temp, mask = lime_exp.get_image_and_mask(\n",
        "    label=top_label,\n",
        "    positive_only=True,\n",
        "    num_features=8,      # number of superpixels to show\n",
        "    hide_rest=False\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "# Original image\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.title(f\"Original\\nTrue: {true_label}\")\n",
        "\n",
        "# LIME explanation\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(mark_boundaries(temp / max(temp.max(), 1e-8), mask))\n",
        "pred_label = class_names[top_label]\n",
        "plt.axis(\"off\")\n",
        "plt.title(f\"LIME ‚Äì Evidence for: {pred_label}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "lime_path = os.path.join(RESULTS_DIR, f\"lime_explanation_idx_{idx}.png\")\n",
        "plt.savefig(lime_path, dpi=200)\n",
        "plt.show()\n",
        "print(f\"üíæ LIME explanation saved to: {lime_path}\")\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# 3. Integrated Gradients (IG) ‚Äì Pixel-level attributions\n",
        "# ===============================================================\n",
        "\n",
        "IMG_H, IMG_W, IMG_C = image.shape\n",
        "\n",
        "def integrated_gradients(\n",
        "    input_image,\n",
        "    target_class_index,\n",
        "    baseline=None,\n",
        "    m_steps=50,\n",
        "):\n",
        "    \"\"\"\n",
        "    Compute Integrated Gradients for a single image and target class.\n",
        "\n",
        "    Args:\n",
        "        input_image: (H, W, C) image in [0,1].\n",
        "        target_class_index: int, index of class for which IG is computed.\n",
        "        baseline: baseline image (H, W, C). If None, uses black image.\n",
        "        m_steps: number of interpolation steps between baseline and image.\n",
        "\n",
        "    Returns:\n",
        "        ig_attributions: (H, W, C) attributions.\n",
        "    \"\"\"\n",
        "    if baseline is None:\n",
        "        baseline = np.zeros_like(input_image).astype(\"float32\")\n",
        "\n",
        "    # Ensure float32\n",
        "    input_image = input_image.astype(\"float32\")\n",
        "    baseline = baseline.astype(\"float32\")\n",
        "\n",
        "    # Generate scaled inputs\n",
        "    interpolated_images = [\n",
        "        baseline + (float(k) / m_steps) * (input_image - baseline)\n",
        "        for k in range(1, m_steps + 1)\n",
        "    ]\n",
        "    interpolated_images = np.stack(interpolated_images, axis=0)  # (m_steps, H, W, C)\n",
        "\n",
        "    # Compute gradients for each interpolated image\n",
        "    interpolated_tensor = tf.convert_to_tensor(interpolated_images)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(interpolated_tensor)\n",
        "        preds = model(interpolated_tensor)                    # (m_steps, num_classes)\n",
        "        probs = preds[:, target_class_index]                  # (m_steps,)\n",
        "\n",
        "    grads = tape.gradient(probs, interpolated_tensor).numpy() # (m_steps, H, W, C)\n",
        "\n",
        "    # Average gradients across steps\n",
        "    avg_grads = grads.mean(axis=0)                            # (H, W, C)\n",
        "\n",
        "    # Integrated gradients: (input - baseline) * average_gradient\n",
        "    ig = (input_image - baseline) * avg_grads                 # (H, W, C)\n",
        "\n",
        "    return ig\n",
        "\n",
        "\n",
        "# ---- Run IG for the same image used in LIME ----\n",
        "\n",
        "# Get predicted class for this image\n",
        "pred_probs = model.predict(image[None, ...], verbose=0)[0]\n",
        "pred_class_idx = int(np.argmax(pred_probs))\n",
        "pred_class_name = class_names[pred_class_idx]\n",
        "\n",
        "print(f\"\\nüßÆ Integrated Gradients for test index {idx}\")\n",
        "print(f\"True label: {true_label} | Predicted: {pred_class_name} (p={pred_probs[pred_class_idx]:.3f})\")\n",
        "\n",
        "# Compute IG\n",
        "ig_attributions = integrated_gradients(\n",
        "    input_image=image,\n",
        "    target_class_index=pred_class_idx,\n",
        "    baseline=None,   # black baseline\n",
        "    m_steps=50\n",
        ")  # (H, W, C)\n",
        "\n",
        "# Convert to a single-channel heatmap by aggregating over colour channels\n",
        "ig_abs = np.abs(ig_attributions).mean(axis=-1)  # (H, W)\n",
        "\n",
        "# Normalise to [0,1] for display\n",
        "ig_min, ig_max = ig_abs.min(), ig_abs.max()\n",
        "heatmap = (ig_abs - ig_min) / (ig_max - ig_min + 1e-8)\n",
        "\n",
        "# ------------------------------------------------\n",
        "# Plot IG heatmap and overlay\n",
        "# ------------------------------------------------\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Heatmap alone\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(heatmap, cmap=\"inferno\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Integrated Gradients\\nHeatmap\")\n",
        "\n",
        "# Original image\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Original Image\")\n",
        "\n",
        "# Overlay\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(image)\n",
        "plt.imshow(heatmap, cmap=\"inferno\", alpha=0.5)\n",
        "plt.axis(\"off\")\n",
        "plt.title(f\"IG Overlay\\nPred: {pred_class_name}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "ig_path = os.path.join(RESULTS_DIR, f\"ig_explanation_idx_{idx}.png\")\n",
        "plt.savefig(ig_path, dpi=200)\n",
        "plt.show()\n",
        "\n",
        "print(f\"üíæ Integrated Gradients explanation saved to: {ig_path}\")\n"
      ],
      "metadata": {
        "id": "A9wk5UtkOu69"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}