{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcU5giwpDy6J"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# üìò PHASE 4: Model Evaluation & Visualization\n",
        "# ==========================================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix,\n",
        "    balanced_accuracy_score, accuracy_score\n",
        ")\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# --------------------------------------\n",
        "# 1Ô∏è‚É£ Mount Drive and Set Paths\n",
        "# --------------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_path = \"/content/drive/MyDrive\"\n",
        "model_path = os.path.join(base_path, \"AML2_Project_Models/cnn_model.h5\")\n",
        "data_path  = os.path.join(base_path, \"AML2_Project_Preprocessed\")\n",
        "\n",
        "# Load model and test data\n",
        "model = load_model(model_path)\n",
        "X_test = np.load(os.path.join(data_path, \"X_test.npy\"))\n",
        "y_test = np.load(os.path.join(data_path, \"y_test.npy\"))\n",
        "\n",
        "class_names = ['NEV', 'ACK', 'SEK', 'BCC', 'MEL', 'SCC']\n",
        "\n",
        "print(\"‚úÖ Model & data loaded successfully!\")\n",
        "print(f\"Test data shape: {X_test.shape}, Labels: {y_test.shape}\")\n",
        "\n",
        "# --------------------------------------\n",
        "# 2Ô∏è‚É£ Load Training History (optional)\n",
        "# --------------------------------------\n",
        "import pickle\n",
        "history_path = os.path.join(base_path, \"AML2_Project_Models/training_history.pkl\")\n",
        "\n",
        "if os.path.exists(history_path):\n",
        "    with open(history_path, 'rb') as f:\n",
        "        history = pickle.load(f)\n",
        "    print(\"‚úÖ Training history loaded!\")\n",
        "else:\n",
        "    history = None\n",
        "    print(\"‚ö†Ô∏è History file not found. Skipping training curves.\")\n",
        "\n",
        "# --------------------------------------\n",
        "# 3Ô∏è‚É£ Plot Training Curves (if available)\n",
        "# --------------------------------------\n",
        "if history:\n",
        "    plt.figure(figsize=(12,5))\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history['val_accuracy'], label='Val Accuracy')\n",
        "    plt.title(\"Model Accuracy\")\n",
        "    plt.xlabel(\"Epochs\"); plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history['loss'], label='Train Loss')\n",
        "    plt.plot(history['val_loss'], label='Val Loss')\n",
        "    plt.title(\"Model Loss\")\n",
        "    plt.xlabel(\"Epochs\"); plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# --------------------------------------\n",
        "# 4Ô∏è‚É£ Evaluate on Test Set\n",
        "# --------------------------------------\n",
        "print(\"\\nüîç Evaluating model on test data...\")\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# FIX: Handle label format automatically\n",
        "if len(y_test.shape) == 1:\n",
        "    y_true = y_test\n",
        "else:\n",
        "    y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Compute metrics\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
        "\n",
        "print(f\"\\n‚úÖ Standard Accuracy: {acc*100:.2f}%\")\n",
        "print(f\"‚úÖ Balanced Accuracy: {bal_acc*100:.2f}%\\n\")\n",
        "\n",
        "print(\"üìä Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "# --------------------------------------\n",
        "# 5Ô∏è‚É£ Confusion Matrix\n",
        "# --------------------------------------\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# --------------------------------------\n",
        "# 6Ô∏è‚É£ Visualise Random Predictions\n",
        "# --------------------------------------\n",
        "import random\n",
        "\n",
        "def plot_predictions(X, y_true, y_pred, class_names, n=9):\n",
        "    idxs = random.sample(range(len(X)), n)\n",
        "    plt.figure(figsize=(12,12))\n",
        "    for i, idx in enumerate(idxs):\n",
        "        plt.subplot(3,3,i+1)\n",
        "        plt.imshow(X[idx])\n",
        "        true_label = class_names[y_true[idx]]\n",
        "        pred_label = class_names[y_pred[idx]]\n",
        "        color = \"green\" if true_label == pred_label else \"red\"\n",
        "        plt.title(f\"True: {true_label}\\nPred: {pred_label}\", color=color)\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_predictions(X_test, y_true, y_pred, class_names)\n",
        "\n",
        "# --------------------------------------\n",
        "# 7Ô∏è‚É£ Accuracy Comparison Bar Plot\n",
        "# --------------------------------------\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar([\"Standard Accuracy\", \"Balanced Accuracy\"], [acc*100, bal_acc*100],\n",
        "        color=[\"skyblue\", \"orange\"])\n",
        "plt.title(\"Accuracy Comparison\")\n",
        "plt.ylabel(\"Percentage (%)\")\n",
        "for i, v in enumerate([acc*100, bal_acc*100]):\n",
        "    plt.text(i, v + 1, f\"{v:.2f}%\", ha='center', fontweight='bold')\n",
        "plt.ylim(0, 100)\n",
        "plt.show()\n",
        "\n",
        "# --------------------------------------\n",
        "# 8Ô∏è‚É£ Save Evaluation Results\n",
        "# --------------------------------------\n",
        "results_dir = os.path.join(base_path, \"AML2_Project_Results\")\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "np.save(os.path.join(results_dir, \"y_true.npy\"), y_true)\n",
        "np.save(os.path.join(results_dir, \"y_pred.npy\"), y_pred)\n",
        "\n",
        "print(f\"\\n‚úÖ Evaluation results saved to: {results_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ======================================================\n",
        "# üìò PHASE 5: Explainable AI ‚Äì LIME + SHAP Visualization\n",
        "# ======================================================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# --------------------------------------------\n",
        "# 1Ô∏è‚É£ Mount Drive and Load Model + Data\n",
        "# --------------------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_path = \"/content/drive/MyDrive\"\n",
        "model_path = os.path.join(base_path, \"AML2_Project_Models/cnn_model.h5\")\n",
        "data_path  = os.path.join(base_path, \"AML2_Project_Preprocessed\")\n",
        "\n",
        "model = load_model(model_path)\n",
        "X_test = np.load(os.path.join(data_path, \"X_test.npy\"))\n",
        "y_test = np.load(os.path.join(data_path, \"y_test.npy\"))\n",
        "\n",
        "class_names = ['NEV', 'ACK', 'SEK', 'BCC', 'MEL', 'SCC']\n",
        "\n",
        "# Ensure y_test is integer encoded\n",
        "if len(y_test.shape) == 1:\n",
        "    y_true = y_test\n",
        "else:\n",
        "    y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"‚úÖ Model and data loaded successfully.\")\n",
        "print(f\"Test shape: {X_test.shape}, Labels: {y_true.shape}\")\n",
        "\n",
        "# --------------------------------------------\n",
        "# 2Ô∏è‚É£ Choose Samples to Explain\n",
        "# --------------------------------------------\n",
        "# Randomly pick 5 test images\n",
        "sample_idxs = random.sample(range(len(X_test)), 5)\n",
        "X_samples = X_test[sample_idxs]\n",
        "y_samples = y_true[sample_idxs]\n",
        "\n",
        "# Model predictions\n",
        "pred_probs = model.predict(X_samples)\n",
        "y_preds = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# --------------------------------------------\n",
        "# 3Ô∏è‚É£ Local Explanation with LIME\n",
        "# --------------------------------------------\n",
        "!pip install lime --quiet\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import mark_boundaries\n",
        "\n",
        "explainer = lime_image.LimeImageExplainer()\n",
        "\n",
        "for i, idx in enumerate(sample_idxs):\n",
        "    explanation = explainer.explain_instance(\n",
        "        X_test[idx].astype('double'),\n",
        "        model.predict,\n",
        "        top_labels=1,\n",
        "        hide_color=0,\n",
        "        num_samples=1000\n",
        "    )\n",
        "\n",
        "    temp, mask = explanation.get_image_and_mask(\n",
        "        label=y_preds[i],\n",
        "        positive_only=False,\n",
        "        hide_rest=False,\n",
        "        num_features=5,\n",
        "        min_weight=0.0\n",
        "    )\n",
        "\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(X_test[idx])\n",
        "    plt.title(f\"Original\\nTrue: {class_names[y_true[idx]]}\\nPred: {class_names[y_preds[i]]}\")\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(mark_boundaries(temp/255.0, mask))\n",
        "    plt.title(\"LIME Explanation\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# --------------------------------------------\n",
        "# 4Ô∏è‚É£ Global Explanation with SHAP\n",
        "# --------------------------------------------\n",
        "!pip install shap --quiet\n",
        "import shap\n",
        "\n",
        "# Compute SHAP values for a subset of test images\n",
        "subset_idx = np.random.choice(len(X_test), 50, replace=False)\n",
        "X_subset = X_test[subset_idx]\n",
        "\n",
        "# Select 20 background samples for reference\n",
        "background = X_subset[:20]\n",
        "\n",
        "# Use GradientExplainer for CNN models\n",
        "explainer = shap.GradientExplainer(model, background)\n",
        "\n",
        "# Calculate SHAP values for 10 test samples\n",
        "shap_values = explainer.shap_values(X_subset[20:30])\n",
        "\n",
        "# Normalise SHAP values for better visual contrast\n",
        "shap_values = [sv / (np.max(np.abs(sv)) + 1e-8) for sv in shap_values]\n",
        "\n",
        "# Plot global SHAP image summary\n",
        "plt.title(\"SHAP Summary ‚Äì Global Feature Influence (Normalised)\")\n",
        "shap.image_plot(shap_values, X_subset[20:30])\n",
        "\n",
        "# --------------------------------------------\n",
        "# 5Ô∏è‚É£ Save Results\n",
        "# --------------------------------------------\n",
        "results_dir = os.path.join(base_path, \"AML2_Project_Results\")\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "np.save(os.path.join(results_dir, \"shap_values.npy\"), shap_values)\n",
        "\n",
        "print(f\"‚úÖ Explanations saved to: {results_dir}\")\n"
      ],
      "metadata": {
        "id": "0mJvwFzJD4Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --------------------------------------------\n",
        "# Phase 6 ‚Äì Model Summary & Report\n",
        "# --------------------------------------------\n",
        "\n",
        "# Evaluate model again to refresh metrics\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# If y_test is already integer labels, skip argmax\n",
        "try:\n",
        "    y_true = np.argmax(y_test, axis=1)\n",
        "except:\n",
        "    y_true = y_test\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "report = classification_report(y_true, y_pred, target_names=[f'Class {i}' for i in range(len(np.unique(y_true)))], output_dict=True)\n",
        "conf_mat = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Print and save results\n",
        "print(\"‚úÖ Model Evaluation Summary\\n\")\n",
        "print(json.dumps(report, indent=4))\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_mat)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(7,6))\n",
        "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Confusion Matrix ‚Äì Skin Lesion Classification\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Mv2O3AmpD5US"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}